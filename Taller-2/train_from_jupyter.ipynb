{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de Modelos de Machine Learning para API de Ping√ºinos\n",
    "\n",
    "Este notebook entrena modelos de ML y los guarda en la carpeta compartida `./models` para que la API FastAPI los consuma autom√°ticamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar librer√≠as necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definir configuraci√≥n y rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n\n",
    "MODELS_DIR = Path(\"./models\")\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Features esperadas para los ping√ºinos\n",
    "PENGUIN_FEATURES = [\n",
    "    \"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"\n",
    "]\n",
    "\n",
    "print(f\"üìÅ Directorio de modelos: {MODELS_DIR.absolute()}\")\n",
    "print(f\"üìä Features a usar: {PENGUIN_FEATURES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cargar y explorar el dataset de ping√ºinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset de ping√ºinos de seaborn\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "print(f\"Dataset original: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "print(f\"\\nPrimeras filas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci√≥n del dataset\n",
    "print(\"Informaci√≥n del dataset:\")\n",
    "df.info()\n",
    "print(f\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar datos: eliminar filas con valores faltantes en features importantes\n",
    "df_clean = df.dropna(subset=PENGUIN_FEATURES + [\"species\"])\n",
    "print(f\"Dataset limpio: {df_clean.shape[0]} filas\")\n",
    "\n",
    "# Distribuci√≥n de especies\n",
    "print(\"\\nDistribuci√≥n de especies:\")\n",
    "print(df_clean['species'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de distribuciones\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(PENGUIN_FEATURES):\n",
    "    for species in df_clean['species'].unique():\n",
    "        subset = df_clean[df_clean['species'] == species]\n",
    "        axes[idx].hist(subset[feature], alpha=0.5, label=species, bins=20)\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Frecuencia')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].set_title(f'Distribuci√≥n de {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preparar datos para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar X (features) e y (target)\n",
    "X = df_clean[PENGUIN_FEATURES].astype(float)\n",
    "y = df_clean[\"species\"].astype(\"category\").cat.codes\n",
    "\n",
    "# Guardar mapeo de clases\n",
    "classes = list(df_clean[\"species\"].astype(\"category\").cat.categories)\n",
    "class_mapping = {i: name for i, name in enumerate(classes)}\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\nMapeo de clases:\")\n",
    "for idx, name in class_mapping.items():\n",
    "    print(f\"  {idx}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥n train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape[0]} muestras\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape[0]} muestras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Entrenar modelo KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline KNN con escalado\n",
    "knn_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "# Entrenar\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predecir\n",
    "y_pred_knn = knn_pipeline.predict(X_test)\n",
    "\n",
    "# M√©tricas\n",
    "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "knn_f1 = f1_score(y_test, y_pred_knn, average=\"macro\")\n",
    "\n",
    "print(\"üéØ Modelo KNN entrenado:\")\n",
    "print(f\"  - Accuracy: {knn_accuracy:.4f}\")\n",
    "print(f\"  - F1-score (macro): {knn_f1:.4f}\")\n",
    "print(\"\\nReporte de clasificaci√≥n:\")\n",
    "print(classification_report(y_test, y_pred_knn, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Entrenar modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Random Forest (no necesita escalado)\n",
    "rf_pipeline = Pipeline([\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "])\n",
    "\n",
    "# Entrenar\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predecir\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "\n",
    "# M√©tricas\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_f1 = f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "\n",
    "print(\"üå≤ Modelo Random Forest entrenado:\")\n",
    "print(f\"  - Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"  - F1-score (macro): {rf_f1:.4f}\")\n",
    "print(\"\\nReporte de clasificaci√≥n:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Entrenar modelo SVM (adicional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline SVM con escalado\n",
    "svm_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", SVC(kernel='rbf', probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# Entrenar\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predecir\n",
    "y_pred_svm = svm_pipeline.predict(X_test)\n",
    "\n",
    "# M√©tricas\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "svm_f1 = f1_score(y_test, y_pred_svm, average=\"macro\")\n",
    "\n",
    "print(\"üîÆ Modelo SVM entrenado:\")\n",
    "print(f\"  - Accuracy: {svm_accuracy:.4f}\")\n",
    "print(f\"  - F1-score (macro): {svm_f1:.4f}\")\n",
    "print(\"\\nReporte de clasificaci√≥n:\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Guardar modelos en la carpeta compartida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelos como archivos .pkl\n",
    "joblib.dump(knn_pipeline, MODELS_DIR / \"knn.pkl\")\n",
    "joblib.dump(rf_pipeline, MODELS_DIR / \"rf.pkl\")\n",
    "joblib.dump(svm_pipeline, MODELS_DIR / \"svm.pkl\")\n",
    "\n",
    "print(\"‚úÖ Modelos guardados:\")\n",
    "print(f\"  - {MODELS_DIR}/knn.pkl\")\n",
    "print(f\"  - {MODELS_DIR}/rf.pkl\")\n",
    "print(f\"  - {MODELS_DIR}/svm.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Crear archivo de metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear metadata con informaci√≥n sobre los modelos\n",
    "metadata = {\n",
    "    \"classes\": classes,\n",
    "    \"feature_order\": PENGUIN_FEATURES,\n",
    "    \"models\": {\n",
    "        \"knn.pkl\": {\n",
    "            \"accuracy\": float(knn_accuracy),\n",
    "            \"f1_macro\": float(knn_f1)\n",
    "        },\n",
    "        \"rf.pkl\": {\n",
    "            \"accuracy\": float(rf_accuracy),\n",
    "            \"f1_macro\": float(rf_f1)\n",
    "        },\n",
    "        \"svm.pkl\": {\n",
    "            \"accuracy\": float(svm_accuracy),\n",
    "            \"f1_macro\": float(svm_f1)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar metadata\n",
    "with open(MODELS_DIR / \"model_metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"üìÑ Metadata guardada en model_metadata.json\")\n",
    "print(json.dumps(metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Verificar modelos guardados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar archivos en la carpeta models\n",
    "print(\"üìÅ Contenido de ./models:\")\n",
    "for file in sorted(MODELS_DIR.iterdir()):\n",
    "    size = file.stat().st_size\n",
    "    print(f\"  - {file.name} ({size:,} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Probar la API con los modelos entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "# Esperar un momento para asegurar que la API detecte los nuevos modelos\n",
    "time.sleep(2)\n",
    "\n",
    "# URL de la API (usando nombre del servicio Docker)\n",
    "API_URL = \"http://api:8000\"\n",
    "\n",
    "try:\n",
    "    # Verificar salud de la API\n",
    "    response = requests.get(f\"{API_URL}/health\")\n",
    "    print(\"üè• Estado de la API:\")\n",
    "    print(json.dumps(response.json(), indent=2))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error conectando con la API: {e}\")\n",
    "    print(\"Nota: Si est√°s ejecutando esto localmente (no en Docker), cambia API_URL a 'http://localhost:8000'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Listar modelos disponibles\n",
    "    response = requests.get(f\"{API_URL}/models\")\n",
    "    print(\"ü§ñ Modelos disponibles en la API:\")\n",
    "    print(json.dumps(response.json(), indent=2))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer una predicci√≥n de prueba\n",
    "sample_penguin = {\n",
    "    \"bill_length_mm\": 44.5,\n",
    "    \"bill_depth_mm\": 17.1,\n",
    "    \"flipper_length_mm\": 200,\n",
    "    \"body_mass_g\": 4200\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Predicci√≥n con todos los modelos\n",
    "    response = requests.post(f\"{API_URL}/predict\", json=sample_penguin)\n",
    "    print(\"üîÆ Predicciones con todos los modelos:\")\n",
    "    predictions = response.json()\n",
    "    \n",
    "    for pred in predictions['predictions']:\n",
    "        print(f\"\\nüìä Modelo: {pred['model']}\")\n",
    "        print(f\"   Predicci√≥n: {pred['prediction']}\")\n",
    "        if 'probabilities' in pred:\n",
    "            print(\"   Probabilidades:\")\n",
    "            for species, prob in pred['probabilities'].items():\n",
    "                print(f\"     - {species}: {prob:.3f}\")\n",
    "                \n",
    "except Exception as e:\n",
    "    print(f\"Error haciendo predicci√≥n: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ ¬°Felicidades!\n",
    "\n",
    "Has completado el entrenamiento de modelos desde JupyterLab. Los modelos est√°n guardados en `./models` y la API FastAPI puede usarlos para hacer predicciones.\n",
    "\n",
    "### Pr√≥ximos pasos:\n",
    "1. Experimenta con otros algoritmos (Gradient Boosting, Neural Networks, etc.)\n",
    "2. Ajusta hiperpar√°metros para mejorar el rendimiento\n",
    "3. Agrega validaci√≥n cruzada\n",
    "4. Implementa feature engineering\n",
    "5. Crea visualizaciones m√°s avanzadas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
