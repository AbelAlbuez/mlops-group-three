{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üêß Experimentos MLflow - Palmer Penguins\n",
    "\n",
    "Este notebook implementa:\n",
    "1. Verificaci√≥n de servicios y bucket S3\n",
    "2. Carga de datos en MySQL (penguins_raw)\n",
    "3. Preprocesamiento y generaci√≥n de datos limpios (penguins_clean)\n",
    "4. ‚â•20 experimentos con diferentes modelos e hiperpar√°metros\n",
    "5. Registro del mejor modelo en MLflow Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Patch aplicado para compatibilidad con SQLAlchemy 2.0\n"
     ]
    }
   ],
   "source": [
    "# Fix de compatibilidad para SQLAlchemy 2.0\n",
    "import sqlalchemy\n",
    "from sqlalchemy import text as sql_text\n",
    "\n",
    "# Monkey patch para compatibilidad\n",
    "original_execute = sqlalchemy.engine.Connection.execute\n",
    "\n",
    "def patched_execute(self, statement, *args, **kwargs):\n",
    "    if isinstance(statement, str):\n",
    "        statement = sql_text(statement)\n",
    "    return original_execute(self, statement, *args, **kwargs)\n",
    "\n",
    "sqlalchemy.engine.Connection.execute = patched_execute\n",
    "\n",
    "print(\"‚úÖ Patch aplicado para compatibilidad con SQLAlchemy 2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI: http://mlflow:5000\n"
     ]
    }
   ],
   "source": [
    "# Importaciones necesarias\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, ClientError\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine, text\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar MLflow\n",
    "mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI', 'http://mlflow:5000'))\n",
    "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Verificar configuraci√≥n y crear bucket si es necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Bucket 'mlflows3' no existe. Intentando crear...\n",
      "‚úÖ Bucket 'mlflows3' creado exitosamente\n"
     ]
    }
   ],
   "source": [
    "# Verificar y crear bucket S3 si es necesario\n",
    "def verify_s3_bucket():\n",
    "    \"\"\"Verifica que el bucket mlflows3 existe, intenta crearlo si no existe\"\"\"\n",
    "    try:\n",
    "        # Configurar cliente S3\n",
    "        s3_client = boto3.client(\n",
    "            's3',\n",
    "            endpoint_url=os.getenv('MLFLOW_S3_ENDPOINT_URL', 'http://minio:9000'),\n",
    "            aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID', 'admin'),\n",
    "            aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY', 'supersecret'),\n",
    "            region_name=os.getenv('AWS_DEFAULT_REGION', 'us-east-1')\n",
    "        )\n",
    "        \n",
    "        # Verificar si el bucket existe\n",
    "        try:\n",
    "            s3_client.head_bucket(Bucket='mlflows3')\n",
    "            print(\"‚úÖ Bucket 'mlflows3' existe y est√° accesible\")\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            error_code = int(e.response['Error']['Code'])\n",
    "            if error_code == 404:\n",
    "                print(\"‚ö†Ô∏è  Bucket 'mlflows3' no existe. Intentando crear...\")\n",
    "                try:\n",
    "                    s3_client.create_bucket(Bucket='mlflows3')\n",
    "                    print(\"‚úÖ Bucket 'mlflows3' creado exitosamente\")\n",
    "                    return True\n",
    "                except Exception as create_error:\n",
    "                    print(f\"‚ùå Error al crear bucket: {create_error}\")\n",
    "                    return False\n",
    "            else:\n",
    "                print(f\"‚ùå Error al verificar bucket: {e}\")\n",
    "                return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error de conexi√≥n S3: {e}\")\n",
    "        return False\n",
    "\n",
    "# Verificar bucket antes de continuar\n",
    "bucket_ready = verify_s3_bucket()\n",
    "\n",
    "if not bucket_ready:\n",
    "    print(\"\\n‚ö†Ô∏è  ADVERTENCIA: El bucket S3 no est√° disponible.\")\n",
    "    print(\"Los experimentos pueden fallar al guardar artefactos.\")\n",
    "    print(\"Intenta ejecutar en una terminal:\")\n",
    "    print(\"docker exec mlflow-minio mc mb myminio/mlflows3\")\n",
    "    print(\"docker exec mlflow-minio mc anonymous set download myminio/mlflows3\")\n",
    "    print(\"\\nEsperando 30 segundos antes de continuar...\")\n",
    "    time.sleep(30)\n",
    "    # Intentar una vez m√°s\n",
    "    bucket_ready = verify_s3_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de conexi√≥n a MySQL\n",
    "MYSQL_CONFIG = {\n",
    "    'host': os.getenv('MYSQL_HOST', 'mysql'),\n",
    "    'port': int(os.getenv('MYSQL_PORT', 3306)),\n",
    "    'user': os.getenv('MYSQL_USER', 'penguins'),\n",
    "    'password': os.getenv('MYSQL_PASSWORD', 'penguins123'),\n",
    "    'database': os.getenv('MYSQL_DATABASE', 'penguins_db')\n",
    "}\n",
    "\n",
    "# Crear engine de SQLAlchemy\n",
    "engine = create_engine(\n",
    "    f\"mysql+pymysql://{MYSQL_CONFIG['user']}:{MYSQL_CONFIG['password']}@\"\n",
    "    f\"{MYSQL_CONFIG['host']}:{MYSQL_CONFIG['port']}/{MYSQL_CONFIG['database']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar datos crudos en MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado desde palmerpenguins\n",
      "Shape: (344, 8)\n",
      "Columnas: ['species', 'island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex', 'year']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "0       3750.0    male  2007  \n",
       "1       3800.0  female  2007  \n",
       "2       3250.0  female  2007  \n",
       "3          NaN     NaN  2007  \n",
       "4       3450.0  female  2007  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar dataset de penguins\n",
    "try:\n",
    "    from palmerpenguins import load_penguins\n",
    "    df_raw = load_penguins()\n",
    "    print(\"Dataset cargado desde palmerpenguins\")\n",
    "except:\n",
    "    import seaborn as sns\n",
    "    df_raw = sns.load_dataset('penguins')\n",
    "    print(\"Dataset cargado desde seaborn\")\n",
    "\n",
    "print(f\"Shape: {df_raw.shape}\")\n",
    "print(f\"Columnas: {df_raw.columns.tolist()}\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla penguins_raw limpiada\n",
      "‚úì 344 registros insertados en penguins_raw\n"
     ]
    }
   ],
   "source": [
    "# Limpiar tabla penguins_raw\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(\"TRUNCATE TABLE penguins_raw\")\n",
    "    conn.commit()\n",
    "print(\"Tabla penguins_raw limpiada\")\n",
    "\n",
    "# Insertar datos crudos\n",
    "df_raw.to_sql('penguins_raw', engine, if_exists='append', index=False)\n",
    "print(f\"‚úì {len(df_raw)} registros insertados en penguins_raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocesar datos y generar penguins_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos le√≠dos: (344, 10)\n",
      "Despu√©s de eliminar nulos: (342, 10)\n",
      "Mapeo de especies: {0: 'Adelie', 1: 'Chinstrap', 2: 'Gentoo'}\n"
     ]
    }
   ],
   "source": [
    "# Leer datos desde MySQL\n",
    "df_from_db = pd.read_sql(\"SELECT * FROM penguins_raw\", engine)\n",
    "print(f\"Datos le√≠dos: {df_from_db.shape}\")\n",
    "\n",
    "# Eliminar filas con valores nulos en features cr√≠ticas\n",
    "critical_features = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'species']\n",
    "df_clean = df_from_db.dropna(subset=critical_features)\n",
    "print(f\"Despu√©s de eliminar nulos: {df_clean.shape}\")\n",
    "\n",
    "# Codificar variable objetivo\n",
    "label_encoder = LabelEncoder()\n",
    "df_clean['species_encoded'] = label_encoder.fit_transform(df_clean['species'])\n",
    "species_mapping = {i: sp for i, sp in enumerate(label_encoder.classes_)}\n",
    "print(f\"Mapeo de especies: {species_mapping}\")\n",
    "\n",
    "# Rellenar valores faltantes opcionales\n",
    "df_clean['sex'] = df_clean['sex'].fillna('Unknown')\n",
    "df_clean['year'] = df_clean['year'].fillna(df_clean['year'].median())\n",
    "\n",
    "# Agregar timestamp\n",
    "df_clean['processed_at'] = pd.Timestamp.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì 342 registros insertados en penguins_clean\n"
     ]
    }
   ],
   "source": [
    "# Limpiar e insertar en penguins_clean\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(\"TRUNCATE TABLE penguins_clean\")\n",
    "    conn.commit()\n",
    "\n",
    "df_clean.to_sql('penguins_clean', engine, if_exists='append', index=False)\n",
    "print(f\"‚úì {len(df_clean)} registros insertados en penguins_clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparar datos para Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (273, 4)\n",
      "Test set: (69, 4)\n",
      "Distribuci√≥n de clases en train: [121  54  98]\n"
     ]
    }
   ],
   "source": [
    "# Preparar features y target\n",
    "feature_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "X = df_clean[feature_cols].values\n",
    "y = df_clean['species_encoded'].values\n",
    "\n",
    "# Divisi√≥n train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Distribuci√≥n de clases en train: {np.bincount(y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experimentos con MLflow (‚â•20 runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento: penguins-classification (ID: 1)\n"
     ]
    }
   ],
   "source": [
    "# Crear experimento en MLflow\n",
    "experiment_name = \"penguins-classification\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Obtener ID del experimento\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "print(f\"Experimento: {experiment_name} (ID: {experiment.experiment_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para entrenar modelo con manejo de errores\n",
    "def train_and_log_model(model, model_name, run_name, params, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Entrena un modelo y lo registra en MLflow con manejo de errores\"\"\"\n",
    "    try:\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            # Log parameters\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_param(\"model_type\", model_name)\n",
    "            \n",
    "            # Entrenar modelo\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Predicciones\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # M√©tricas\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "            mlflow.log_metric(\"f1_score\", f1)\n",
    "            \n",
    "            # Intentar log model con reintentos\n",
    "            max_retries = 3\n",
    "            for retry in range(max_retries):\n",
    "                try:\n",
    "                    mlflow.sklearn.log_model(\n",
    "                        model, \n",
    "                        \"model\",\n",
    "                        input_example=X_train[:1],\n",
    "                        signature=mlflow.models.infer_signature(X_train, y_train)\n",
    "                    )\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    if \"NoSuchBucket\" in str(e) and retry < max_retries - 1:\n",
    "                        print(f\"‚ö†Ô∏è  Error con bucket S3, reintentando en 5s... ({retry+1}/{max_retries})\")\n",
    "                        time.sleep(5)\n",
    "                    else:\n",
    "                        print(f\"‚ùå Error al guardar modelo: {e}\")\n",
    "                        print(\"   El modelo se entren√≥ pero no se pudo guardar en S3\")\n",
    "            \n",
    "            print(f\"{run_name}: Accuracy={accuracy:.4f}, F1={f1:.4f}\")\n",
    "            return accuracy, f1\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en {run_name}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentos 1-5: Random Forest con diferentes hiperpar√°metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:04:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_experiment_1: Accuracy=1.0000, F1=1.0000\n",
      "üèÉ View run rf_experiment_1 at: http://mlflow:5000/#/experiments/1/runs/bd5a0c2810934b8da64029bb73e87ce6\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:04:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_experiment_2: Accuracy=1.0000, F1=1.0000\n",
      "üèÉ View run rf_experiment_2 at: http://mlflow:5000/#/experiments/1/runs/21cd87ed6aab4f699769f7d48e2458d9\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:04:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_experiment_3: Accuracy=1.0000, F1=1.0000\n",
      "üèÉ View run rf_experiment_3 at: http://mlflow:5000/#/experiments/1/runs/3f7b8534b72c4f83869867229215f362\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:04:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_experiment_4: Accuracy=1.0000, F1=1.0000\n",
      "üèÉ View run rf_experiment_4 at: http://mlflow:5000/#/experiments/1/runs/9dc3cf3bf32b463582e903463ba74508\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:04:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_experiment_5: Accuracy=1.0000, F1=1.0000\n",
      "üèÉ View run rf_experiment_5 at: http://mlflow:5000/#/experiments/1/runs/478fb460d6b742fc8c48042852c6a3ca\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# Configuraciones de Random Forest\n",
    "rf_configs = [\n",
    "    {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 5},\n",
    "    {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2},\n",
    "    {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 2},\n",
    "    {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 4},\n",
    "    {'n_estimators': 500, 'max_depth': 20, 'min_samples_split': 3}\n",
    "]\n",
    "\n",
    "for i, config in enumerate(rf_configs, 1):\n",
    "    rf = RandomForestClassifier(random_state=42, **config)\n",
    "    train_and_log_model(\n",
    "        rf, \n",
    "        \"RandomForest\", \n",
    "        f\"rf_experiment_{i}\", \n",
    "        config,\n",
    "        X_train, y_train, X_test, y_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentos 6-10: KNN con diferentes valores de k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:04:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_experiment_6: Accuracy=1.0000, F1=1.0000\n",
      "üèÉ View run knn_experiment_6 at: http://mlflow:5000/#/experiments/1/runs/2d7c4a0270c24fbca4b7b73b69f7dafa\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:04:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_experiment_7: Accuracy=1.0000, F1=1.0000\n",
      "üèÉ View run knn_experiment_7 at: http://mlflow:5000/#/experiments/1/runs/b3d5015c47404e6bad85be0b233e4b20\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:04:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_experiment_8: Accuracy=1.0000, F1=1.0000\n",
      "üèÉ View run knn_experiment_8 at: http://mlflow:5000/#/experiments/1/runs/5b4352bf77f24b6b80f4640f6702a34c\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:04:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_experiment_9: Accuracy=0.9855, F1=0.9822\n",
      "üèÉ View run knn_experiment_9 at: http://mlflow:5000/#/experiments/1/runs/b6efd9e4c195479da39ae30d24167379\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:04:53 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_experiment_10: Accuracy=0.9855, F1=0.9822\n",
      "üèÉ View run knn_experiment_10 at: http://mlflow:5000/#/experiments/1/runs/8deb01d08f5d4514854723c1e25ab13b\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# KNN experiments\n",
    "k_values = [3, 5, 7, 10, 15]\n",
    "weights_options = ['uniform', 'distance']\n",
    "\n",
    "exp_num = 6\n",
    "for k in k_values:\n",
    "    for weights in weights_options[:1]:  # Solo 'uniform' para llegar a 5 experimentos\n",
    "        # Crear pipeline con escalado\n",
    "        knn_pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('knn', KNeighborsClassifier(n_neighbors=k, weights=weights))\n",
    "        ])\n",
    "        \n",
    "        params = {'n_neighbors': k, 'weights': weights}\n",
    "        train_and_log_model(\n",
    "            knn_pipeline,\n",
    "            \"KNN\",\n",
    "            f\"knn_experiment_{exp_num}\",\n",
    "            params,\n",
    "            X_train, y_train, X_test, y_test\n",
    "        )\n",
    "        exp_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentos 11-15: SVM con diferentes kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:04:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_experiment_11: Accuracy=1.0000, F1=1.0000\n",
      "üèÉ View run svm_experiment_11 at: http://mlflow:5000/#/experiments/1/runs/38f2d771047241a5982cdf4df631cacd\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:04:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_experiment_12: Accuracy=1.0000, F1=1.0000\n",
      "üèÉ View run svm_experiment_12 at: http://mlflow:5000/#/experiments/1/runs/a8132231562c4b13abf34ae0cc046a11\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:04:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_experiment_13: Accuracy=1.0000, F1=1.0000\n",
      "üèÉ View run svm_experiment_13 at: http://mlflow:5000/#/experiments/1/runs/fe42d9f7ca964501b04ed5988ec360b9\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:04:59 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_experiment_14: Accuracy=1.0000, F1=1.0000\n",
      "üèÉ View run svm_experiment_14 at: http://mlflow:5000/#/experiments/1/runs/3d82b24ca2d74710ad17a89161970687\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:05:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_experiment_15: Accuracy=0.9565, F1=0.9441\n",
      "üèÉ View run svm_experiment_15 at: http://mlflow:5000/#/experiments/1/runs/0aefc43fe09e415abfd243e42208686c\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# SVM experiments\n",
    "svm_configs = [\n",
    "    {'kernel': 'linear', 'C': 0.1},\n",
    "    {'kernel': 'linear', 'C': 1.0},\n",
    "    {'kernel': 'rbf', 'C': 1.0, 'gamma': 'scale'},\n",
    "    {'kernel': 'rbf', 'C': 10.0, 'gamma': 'auto'},\n",
    "    {'kernel': 'poly', 'C': 1.0, 'degree': 3}\n",
    "]\n",
    "\n",
    "for i, config in enumerate(svm_configs, 11):\n",
    "    # Crear pipeline con escalado\n",
    "    svm_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', SVC(probability=True, random_state=42, **config))\n",
    "    ])\n",
    "    \n",
    "    train_and_log_model(\n",
    "        svm_pipeline,\n",
    "        \"SVM\",\n",
    "        f\"svm_experiment_{i}\",\n",
    "        config,\n",
    "        X_train, y_train, X_test, y_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentos 16-20: XGBoost con diferentes configuraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:05:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost_experiment_16: Accuracy=0.9565, F1=0.9528\n",
      "üèÉ View run xgboost_experiment_16 at: http://mlflow:5000/#/experiments/1/runs/27dc3d1622224798b2562ee82d1b970b\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:05:04 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost_experiment_17: Accuracy=0.9565, F1=0.9528\n",
      "üèÉ View run xgboost_experiment_17 at: http://mlflow:5000/#/experiments/1/runs/e6f3340c25cb4c9eb6a906ea44630cd0\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:05:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost_experiment_18: Accuracy=0.9710, F1=0.9692\n",
      "üèÉ View run xgboost_experiment_18 at: http://mlflow:5000/#/experiments/1/runs/eb427ffbbace430882e5a5fb02f7c24c\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:05:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost_experiment_19: Accuracy=0.9710, F1=0.9653\n",
      "üèÉ View run xgboost_experiment_19 at: http://mlflow:5000/#/experiments/1/runs/b5820f4fe9aa41188471ef6077306c09\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:05:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost_experiment_20: Accuracy=0.9710, F1=0.9653\n",
      "üèÉ View run xgboost_experiment_20 at: http://mlflow:5000/#/experiments/1/runs/7a2ae89a3e1e4c15bc2afc12e2c58fad\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# XGBoost experiments\n",
    "xgb_configs = [\n",
    "    {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1},\n",
    "    {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05},\n",
    "    {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.01},\n",
    "    {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.1},\n",
    "    {'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.3}\n",
    "]\n",
    "\n",
    "for i, config in enumerate(xgb_configs, 16):\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        random_state=42,\n",
    "        **config\n",
    "    )\n",
    "    \n",
    "    train_and_log_model(\n",
    "        xgb_model,\n",
    "        \"XGBoost\",\n",
    "        f\"xgboost_experiment_{i}\",\n",
    "        config,\n",
    "        X_train, y_train, X_test, y_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentos adicionales 21-25: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:05:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm_experiment_21: Accuracy=0.9565, F1=0.9528\n",
      "üèÉ View run lightgbm_experiment_21 at: http://mlflow:5000/#/experiments/1/runs/4d1e2592fe724eaa923d58cd0eb2c340\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:05:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm_experiment_22: Accuracy=0.9710, F1=0.9653\n",
      "üèÉ View run lightgbm_experiment_22 at: http://mlflow:5000/#/experiments/1/runs/393e345fb4d248ccbf0743ba96feaa9a\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:05:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm_experiment_23: Accuracy=0.9565, F1=0.9528\n",
      "üèÉ View run lightgbm_experiment_23 at: http://mlflow:5000/#/experiments/1/runs/b59f1936c750451a9be0bf71ddd58a75\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:05:16 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm_experiment_24: Accuracy=0.9855, F1=0.9817\n",
      "üèÉ View run lightgbm_experiment_24 at: http://mlflow:5000/#/experiments/1/runs/4fd27a4739a64f10b762e00f7433d631\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/21 20:05:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm_experiment_25: Accuracy=0.9710, F1=0.9653\n",
      "üèÉ View run lightgbm_experiment_25 at: http://mlflow:5000/#/experiments/1/runs/0eb1030532c64a33b3db349f299c1f5d\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# LightGBM experiments para completar ‚â•20\n",
    "lgb_configs = [\n",
    "    {'n_estimators': 100, 'num_leaves': 31, 'learning_rate': 0.1},\n",
    "    {'n_estimators': 200, 'num_leaves': 50, 'learning_rate': 0.05},\n",
    "    {'n_estimators': 150, 'num_leaves': 20, 'learning_rate': 0.15},\n",
    "    {'n_estimators': 300, 'num_leaves': 40, 'learning_rate': 0.01},\n",
    "    {'n_estimators': 250, 'num_leaves': 60, 'learning_rate': 0.08}\n",
    "]\n",
    "\n",
    "for i, config in enumerate(lgb_configs, 21):\n",
    "    lgb_model = lgb.LGBMClassifier(\n",
    "        objective='multiclass',\n",
    "        random_state=42,\n",
    "        verbose=-1,\n",
    "        **config\n",
    "    )\n",
    "    \n",
    "    train_and_log_model(\n",
    "        lgb_model,\n",
    "        \"LightGBM\",\n",
    "        f\"lightgbm_experiment_{i}\",\n",
    "        config,\n",
    "        X_train, y_train, X_test, y_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Seleccionar mejor modelo y registrar en Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor run ID: 3d82b24ca2d74710ad17a89161970687\n",
      "Modelo: SVM\n",
      "F1 Score: 1.0000\n",
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Buscar el mejor run basado en F1 score\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    filter_string=\"\",\n",
    "    order_by=[\"metrics.f1_score DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "\n",
    "if len(runs) > 0:\n",
    "    best_run = runs.iloc[0]\n",
    "    print(f\"Mejor run ID: {best_run['run_id']}\")\n",
    "    print(f\"Modelo: {best_run['params.model_type']}\")\n",
    "    print(f\"F1 Score: {best_run['metrics.f1_score']:.4f}\")\n",
    "    print(f\"Accuracy: {best_run['metrics.accuracy']:.4f}\")\n",
    "else:\n",
    "    print(\"‚ùå No se encontraron runs exitosos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0660426daa64d86a6382a8d77a8e511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747d3120573446a897b8cf9c4e51f4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'penguins-classifier'.\n",
      "2025/09/21 20:05:20 WARNING mlflow.tracking._model_registry.fluent: Run with id 3d82b24ca2d74710ad17a89161970687 has no artifacts at artifact path 'model', registering model based on models:/m-1fe93335053c45f294c6a434f455572b instead\n",
      "2025/09/21 20:05:20 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: penguins-classifier, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo encontrado, procediendo a registrar...\n",
      "‚úÖ Modelo registrado: penguins-classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'penguins-classifier'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versi√≥n del modelo: 1\n",
      "‚úÖ Modelo penguins-classifier v1 promovido a Production\n"
     ]
    }
   ],
   "source": [
    "# Registrar el mejor modelo si existe\n",
    "if len(runs) > 0 and 'artifact_uri' in best_run:\n",
    "    model_name = \"penguins-classifier\"\n",
    "    model_uri = f\"runs:/{best_run['run_id']}/model\"\n",
    "    \n",
    "    # Verificar si el modelo tiene artefactos guardados\n",
    "    try:\n",
    "        # Intentar cargar el modelo para verificar que existe\n",
    "        test_model = mlflow.pyfunc.load_model(model_uri)\n",
    "        print(\"‚úÖ Modelo encontrado, procediendo a registrar...\")\n",
    "        \n",
    "        # Registrar modelo\n",
    "        try:\n",
    "            mlflow.register_model(model_uri, model_name)\n",
    "            print(f\"‚úÖ Modelo registrado: {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Modelo ya existe o error: {e}\")\n",
    "        \n",
    "        # Obtener versi√≥n del modelo\n",
    "        client = mlflow.tracking.MlflowClient()\n",
    "        model_version = client.get_latest_versions(model_name, stages=[\"None\"])[0]\n",
    "        print(f\"Versi√≥n del modelo: {model_version.version}\")\n",
    "        \n",
    "        # Transicionar modelo a Production\n",
    "        client.transition_model_version_stage(\n",
    "            name=model_name,\n",
    "            version=model_version.version,\n",
    "            stage=\"Production\",\n",
    "            archive_existing_versions=True\n",
    "        )\n",
    "        \n",
    "        # A√±adir descripci√≥n al modelo\n",
    "        client.update_model_version(\n",
    "            name=model_name,\n",
    "            version=model_version.version,\n",
    "            description=f\"Mejor modelo para clasificaci√≥n de ping√ºinos. F1={best_run['metrics.f1_score']:.4f}\"\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Modelo {model_name} v{model_version.version} promovido a Production\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå El modelo no tiene artefactos guardados o no se puede cargar: {e}\")\n",
    "        print(\"   Esto puede deberse a problemas con el bucket S3.\")\n",
    "        print(\"   Los experimentos se ejecutaron pero los modelos no se pudieron guardar.\")\n",
    "else:\n",
    "    print(\"‚ùå No hay modelos disponibles para registrar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verificar modelo en Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3075486a3bb5486c853a476c5c8a4875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicci√≥n de prueba:\n",
      "Input: [  44.5   17.1  200.  4200. ]\n",
      "Predicci√≥n: Adelie (c√≥digo: 0)\n"
     ]
    }
   ],
   "source": [
    "# Intentar cargar modelo desde Production si existe\n",
    "try:\n",
    "    model_uri = f\"models:/{model_name}/Production\"\n",
    "    loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "    \n",
    "    # Hacer predicci√≥n de prueba\n",
    "    test_input = pd.DataFrame({\n",
    "        'bill_length_mm': [44.5],\n",
    "        'bill_depth_mm': [17.1],\n",
    "        'flipper_length_mm': [200],\n",
    "        'body_mass_g': [4200]\n",
    "    })\n",
    "    \n",
    "    prediction = loaded_model.predict(test_input)\n",
    "    predicted_species = species_mapping[prediction[0]]\n",
    "    \n",
    "    print(f\"Predicci√≥n de prueba:\")\n",
    "    print(f\"Input: {test_input.values[0]}\")\n",
    "    print(f\"Predicci√≥n: {predicted_species} (c√≥digo: {prediction[0]})\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå No se pudo cargar el modelo desde Production: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä RESUMEN FINAL:\n",
      "- Total de experimentos realizados: 30\n",
      "- Mejor modelo: SVM\n",
      "- F1 Score: 1.0000\n",
      "- Modelo registrado: penguins-classifier\n",
      "- Versi√≥n en Production: 1\n",
      "\n",
      "‚úÖ Pipeline MLflow completado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# Resumen final\n",
    "total_runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "print(f\"\\nüìä RESUMEN FINAL:\")\n",
    "print(f\"- Total de experimentos realizados: {len(total_runs)}\")\n",
    "\n",
    "if len(runs) > 0:\n",
    "    print(f\"- Mejor modelo: {best_run['params.model_type']}\")\n",
    "    print(f\"- F1 Score: {best_run['metrics.f1_score']:.4f}\")\n",
    "    \n",
    "    try:\n",
    "        if 'model_version' in locals():\n",
    "            print(f\"- Modelo registrado: {model_name}\")\n",
    "            print(f\"- Versi√≥n en Production: {model_version.version}\")\n",
    "            print(f\"\\n‚úÖ Pipeline MLflow completado exitosamente!\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è  Pipeline MLflow completado parcialmente\")\n",
    "            print(\"   Los experimentos se ejecutaron pero hubo problemas con el registro del modelo\")\n",
    "    except:\n",
    "        print(f\"\\n‚ö†Ô∏è  Pipeline MLflow completado con advertencias\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No se completaron experimentos exitosamente\")\n",
    "\n",
    "if not bucket_ready:\n",
    "    print(\"\\n‚ö†Ô∏è  NOTA: Hubo problemas con el bucket S3.\")\n",
    "    print(\"   Los modelos pueden no haberse guardado correctamente.\")\n",
    "    print(\"   Verifica la configuraci√≥n de MinIO y vuelve a ejecutar el notebook.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
