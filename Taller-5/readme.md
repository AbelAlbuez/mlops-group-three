# ğŸš€ Taller 5 - Pruebas de Carga con Locust

## ğŸ“‹ DescripciÃ³n

Taller de MLOps enfocado en realizar **pruebas de carga** a una API de inferencia del modelo **Covertype Classification** utilizando Locust, Docker y herramientas de monitoreo.

**Objetivo principal**: Encontrar los recursos mÃ­nimos (CPU/RAM) que soporten **10,000 usuarios concurrentes** con incrementos de 500 usuarios.

---

## ğŸ¯ Objetivos del Taller

1. âœ… **Imagen publicada**: `ogaston/inference-g3:latest` en DockerHub
2. âœ… **Sistema simplificado**: 2 scripts principales (start_all.sh + stop_all.sh)
3. âœ… **Pruebas desde UI**: Todo se configura desde Locust Web UI
4. â­ **Limitar recursos**: CPU y RAM ajustables
5. â­ **Escalar con rÃ©plicas**: MÃºltiples instancias de la API
6. â­ **Documentar resultados**: Tablas, grÃ¡ficos y anÃ¡lisis

---

## ğŸ³ Imagen Docker

### Imagen Publicada en DockerHub

âœ… **Imagen**: `ogaston/inference-g3:latest`  
ğŸ”— **URL**: https://hub.docker.com/r/ogaston/inference-g3

**CaracterÃ­sticas de la imagen:**
- **Modelo**: Covertype Classification (12 features)
- **Framework**: FastAPI + scikit-learn
- **Puerto**: 8000
- **Health Check**: `/health`
- **API Docs**: `/docs` (Swagger UI)
- **Arquitecturas**: AMD64, ARM64

**Uso:**

Para subir toda la infraestructura de la API:

```bash
docker compose up -d --buld
```

---

## ğŸ“ Estructura del Proyecto

```
Taller-5/
â”œâ”€â”€ start_all.sh                        # â­ Script principal de inicio
â”œâ”€â”€ stop_all.sh                         # â­ Script de detenciÃ³n
â”œâ”€â”€ docker-compose.yaml                 # Compose principal (Sistema base)
â”œâ”€â”€ docker-compose.locust-official.yml  # Compose para Locust
â”œâ”€â”€ .env                                # Variables de entorno
â”œâ”€â”€ locustfile.py                       # ConfiguraciÃ³n de pruebas Locust
â”œâ”€â”€ app/
â”‚   â””â”€â”€ train_standalone.py            # Script de entrenamiento
â”œâ”€â”€ mysql/
â”‚   â””â”€â”€ init/
â”‚       â””â”€â”€ 01-create-schema.sql       # Schema de BD
â””â”€â”€ README-SIMPLE.md                    # GuÃ­a rÃ¡pida
```

**Archivos opcionales** (Ãºtiles pero no esenciales):
- `set_resources.sh` - Cambiar recursos dinÃ¡micamente
- `nginx.conf` - Load balancer para mÃºltiples rÃ©plicas
- `.env.sample` - Ejemplo de configuraciÃ³n

---

## ğŸ”§ Requisitos Previos

- **Docker** 20.10+
- **Docker Compose** 2.0+
- **curl** (para health checks)
- **8GB RAM** mÃ­nimo
- **10GB** espacio en disco

### Verificar instalaciÃ³n:
```bash
docker --version
docker compose version
curl --version
```

---

## âš¡ Inicio RÃ¡pido (3 pasos)

### 1ï¸âƒ£ Iniciar servicios
```bash
# Dar permisos de ejecuciÃ³n (solo primera vez)
chmod +x start_all.sh stop_all.sh

# Iniciar servicios con configuraciÃ³n por defecto (medium)
./start_all.sh

# O con configuraciÃ³n especÃ­fica
./start_all.sh quick    # 0.5 CPU, 512M RAM
./start_all.sh medium   # 1.0 CPU, 1G RAM (default)
./start_all.sh load     # 2.0 CPU, 2G RAM
./start_all.sh stress   # 4.0 CPU, 4G RAM
```

### 2ï¸âƒ£ Acceder a Locust UI
Abre tu navegador en: **http://localhost:8089**

### 3ï¸âƒ£ Configurar y ejecutar prueba
En la UI de Locust:
- **Number of users**: 2000 (segÃºn configuraciÃ³n elegida)
- **Spawn rate**: 100 usuarios/segundo
- **Host**: http://inference-api:8000 (ya configurado)
- Click en **"Start swarming"** ğŸš€

---

## ğŸ“Š Configuraciones Disponibles

| ConfiguraciÃ³n | CPU | RAM | Usuarios Recomendados | Uso |
|---------------|-----|-----|-----------------------|-----|
| **quick** | 0.5 | 512M | 500 | Desarrollo/Pruebas rÃ¡pidas |
| **medium** | 1.0 | 1G | 2,000 | Testing (default) |
| **load** | 2.0 | 2G | 5,000 | Pre-producciÃ³n |
| **stress** | 4.0 | 4G | 10,000 | ProducciÃ³n/EstrÃ©s |

---

## ğŸ¯ Flujo de Trabajo del Taller

### Paso 1: ConfiguraciÃ³n Inicial

```bash
# 1. Iniciar con configuraciÃ³n base
./start_all.sh medium

# 2. Verificar que todo funciona
curl http://localhost:8000/health

# 3. Abrir Locust UI
open http://localhost:8089
```

### Paso 2: Ejecutar Pruebas Incrementales

```bash
# En la UI de Locust (http://localhost:8089):

# Prueba 1: 100 usuarios
Number of users: 100
Spawn rate: 10
Click "Start swarming"
â†’ Observar: RPS, latencia, errores

# Prueba 2: 500 usuarios
Click "Stop" â†’ Cambiar a 500 users â†’ "Start swarming"
â†’ Anotar resultados

# Prueba 3: 1000 usuarios
â†’ Continuar incrementando...

# Prueba 4: 2000 usuarios
â†’ Documentar cuando empiecen a aparecer errores
```

### Paso 3: Ajustar Recursos si es Necesario

```bash
# Si la API no soporta la carga actual:

# 1. Detener servicios
./stop_all.sh

# 2. Iniciar con mÃ¡s recursos
./start_all.sh load  # 2 CPU, 2GB RAM

# 3. Repetir pruebas
open http://localhost:8089
```

### Paso 4: Encontrar ConfiguraciÃ³n Ã“ptima

Repetir hasta encontrar el mÃ­nimo de recursos que soporten 10,000 usuarios con:
- âœ… **Failures < 1%**
- âœ… **P95 Latency < 1s**
- âœ… **CPU < 90%**
- âœ… **RAM < 90%**

### Paso 5: Documentar Resultados

Crear tabla con tus hallazgos:

| CPU | RAM | Users | RPS | P95 (ms) | Failures | Resultado |
|-----|-----|-------|-----|----------|----------|-----------|

---

## ğŸ› ï¸ Comandos Ãštiles

### Scripts Principales

```bash
# Iniciar servicios
./start_all.sh [quick|medium|load|stress]

# Ver estado actual
./start_all.sh --status

# Ver logs en tiempo real
./start_all.sh --logs

# Detener servicios
./stop_all.sh

# Detener y limpiar contenedores
./stop_all.sh --clean

# Limpieza completa
./stop_all.sh --all
```

### Comandos Docker Compose

```bash
# Ver estado de contenedores
docker compose -f docker-compose.locust-official.yml ps

# Ver logs
docker compose -f docker-compose.locust-official.yml logs -f

# Ver logs de un servicio especÃ­fico
docker logs inference-api
docker logs locust-master-official

# Ver estadÃ­sticas de recursos
docker stats
```

### Health Checks

```bash
# Verificar API
curl http://localhost:8000/health

# Verificar Locust
curl http://localhost:8089

# Hacer predicciÃ³n de prueba
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "elevation": 2500,
    "aspect": 180,
    "slope": 15,
    "horizontal_distance_to_hydrology": 200,
    "vertical_distance_to_hydrology": 50,
    "horizontal_distance_to_roadways": 1000,
    "hillshade_9am": 200,
    "hillshade_noon": 230,
    "hillshade_3pm": 150,
    "horizontal_distance_to_fire_points": 800,
    "wilderness_area": 1,
    "soil_type": 10
  }'
```

---

## ğŸ”€ Escalamiento con RÃ©plicas

Para probar con mÃºltiples instancias de la API:

```bash
# Escalar a 3 rÃ©plicas
docker compose -f docker-compose.locust-official.yml up -d --scale inference-api=3

# Verificar rÃ©plicas
docker ps | grep inference-api

# Nota: Esto distribuye la carga automÃ¡ticamente entre las rÃ©plicas
```

---

## ğŸ“ˆ Monitoreo en Tiempo Real

### Desde Locust UI (http://localhost:8089)

- **Statistics**: Tabla con RPS, latencias, errores
- **Charts**: GrÃ¡ficos de RPS y tiempos de respuesta
- **Failures**: Detalle de errores
- **Exceptions**: Excepciones capturadas
- **Download Data**: Descargar reportes CSV/HTML

### Desde Docker Stats

```bash
# Ver uso de recursos de todos los contenedores
docker stats

# Solo la API
docker stats inference-api
```

---

## ğŸ“ Guardar Resultados

### Desde Locust UI

1. Durante o despuÃ©s de la prueba, ir a http://localhost:8089
2. Click en **"Download Data"** en el menÃº superior
3. Seleccionar **"Download Report"** para HTML
4. O **"Download Request statistics CSV"** para datos

### Screenshots Importantes

Captura pantallas de:
- Tabla de Statistics con RPS y latencias
- GrÃ¡ficos de Charts (Total RPS y Response Times)
- Docker stats mostrando uso de CPU/RAM
- ConfiguraciÃ³n de recursos usada

---

## ğŸ› Troubleshooting

### Servicios no inician

```bash
# Ver logs completos
docker compose -f docker-compose.locust-official.yml logs

# Verificar puertos en uso
lsof -i :8000
lsof -i :8089

# Limpiar y reiniciar
./stop_all.sh --all
./start_all.sh
```

### API no responde

```bash
# Health check detallado
curl -v http://localhost:8000/health

# Ver logs de la API
docker logs inference-api

# Reiniciar solo la API
docker restart inference-api
```

### Puerto 8089 en uso

```bash
# Ver quÃ© estÃ¡ usando el puerto
lsof -i :8089

# Matar proceso si es necesario
kill -9 <PID>

# O cambiar puerto en docker-compose.locust-official.yml
```

### Locust no conecta a la API

```bash
# Verificar que ambos estÃ¡n en la misma red
docker network inspect taller-5_default

# Si la red no existe, crearla
docker network create taller-5_default

# Reiniciar servicios
./stop_all.sh
./start_all.sh
```

---

## ğŸ§¹ Limpieza

### Detener servicios (mantiene contenedores)

```bash
./stop_all.sh
```

### Limpiar contenedores

```bash
./stop_all.sh --clean
```

### Limpieza completa (todo)

```bash
./stop_all.sh --all
```

### Limpiar sistema Docker

```bash
# Limpiar contenedores detenidos
docker container prune -f

# Limpiar imÃ¡genes no usadas
docker image prune -a -f

# Limpiar volÃºmenes
docker volume prune -f

# Limpieza completa del sistema
docker system prune -a --volumes -f
```

---

## ğŸ”— URLs de Acceso

| Servicio | URL | DescripciÃ³n |
|----------|-----|-------------|
| **Locust UI** | http://localhost:8089 | ğŸ¯ Interfaz principal de pruebas |
| **API** | http://localhost:8000 | API de inferencia |
| **API Health** | http://localhost:8000/health | Health check |
| **API Docs** | http://localhost:8000/docs | Swagger UI |

---

## ğŸ“Š Ejemplo de Payload para Pruebas Manuales

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "elevation": 2500,
    "aspect": 180,
    "slope": 15,
    "horizontal_distance_to_hydrology": 200,
    "vertical_distance_to_hydrology": 50,
    "horizontal_distance_to_roadways": 1000,
    "hillshade_9am": 200,
    "hillshade_noon": 230,
    "hillshade_3pm": 150,
    "horizontal_distance_to_fire_points": 800,
    "wilderness_area": 1,
    "soil_type": 10
  }'
```

Respuesta esperada:
```json
{
  "prediction": 3,
  "confidence": 0.95,
  "model_version": "1.0.0"
}
```

---

## ğŸ‘¥ Equipo

- **Grupo 3**: Abel Albuez Sanchez, Omar Gaston Chalas, Mauricio Morales
- **Imagen Docker**: ogaston/inference-g3:latest
- **Modelo**: Covertype Classification (12 features)

---

## ğŸ“„ Licencia

Este proyecto es parte del curso de MLOps - 2024

---

## âœ… Checklist de ValidaciÃ³n

Antes de entregar el taller, verifica:

- [ ] Imagen publicada en DockerHub
- [ ] Scripts funcionan correctamente (`start_all.sh`, `stop_all.sh`)
- [ ] Locust UI accesible en http://localhost:8089
- [ ] API responde en http://localhost:8000/health
- [ ] Pruebas ejecutadas con diferentes configuraciones
- [ ] Resultados documentados (screenshots + tabla)
- [ ] Tabla de resultados completa (CPU, RAM, Users, RPS, Latencia, Errores)
- [ ] AnÃ¡lisis de 1 vs mÃºltiples instancias (opcional)
- [ ] Screenshots de evidencia
- [ ] Reporte final escrito

---

## ğŸ†˜ Soporte

Para problemas:

1. Revisar secciÃ³n de **Troubleshooting**
2. Ver logs: `./start_all.sh --logs`
3. Verificar estado: `./start_all.sh --status`
4. Consultar **README-SIMPLE.md** para guÃ­a rÃ¡pida

---

## ğŸ’¡ Tips para el Ã‰xito

1. **Empieza con `quick`**: Prueba con recursos mÃ­nimos primero
2. **Incrementa gradualmente**: 100 â†’ 500 â†’ 1000 â†’ 2000 â†’ 5000 â†’ 10000 usuarios
3. **Documenta todo**: Toma screenshots en cada paso
4. **Observa las mÃ©tricas**: RPS, latencia P95, % errores, uso CPU/RAM
5. **Descarga reportes**: Usa "Download Report" en Locust UI
6. **Limpia entre pruebas**: `./stop_all.sh --clean` antes de cambiar recursos

**Â¡Ã‰xito en el taller! ğŸš€**