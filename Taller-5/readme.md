# üöÄ Taller 5 - Pruebas de Carga con Locust

## üìã Descripci√≥n

Taller de MLOps enfocado en realizar **pruebas de carga** a una API de inferencia del modelo **Covertype Classification** utilizando Locust, Docker y herramientas de monitoreo.

**Objetivo principal**: Encontrar los recursos m√≠nimos (CPU/RAM) que soporten **10,000 usuarios concurrentes** con incrementos de 500 usuarios.

---

## üéØ Objetivos del Taller

1. ‚úÖ **Imagen publicada**: `ogaston/inference-g3:latest` en DockerHub
2. ‚úÖ **Docker Compose simple**: Para inferencia b√°sica sin Locust
3. ‚úÖ **Docker Compose con Locust**: Para pruebas de carga
4. ‚≠ê **Limitar recursos**: CPU y RAM ajustables
5. ‚≠ê **Escalar con r√©plicas**: M√∫ltiples instancias de la API
6. ‚≠ê **Documentar resultados**: Tablas, gr√°ficos y an√°lisis

---

## üê≥ Imagen Docker

### Imagen Publicada en DockerHub

‚úÖ **Imagen**: `ogaston/inference-g3:latest`  
üîó **URL**: https://hub.docker.com/r/ogaston/inference-g3

**Caracter√≠sticas de la imagen:**
- **Modelo**: Covertype Classification (12 features)
- **Framework**: FastAPI + scikit-learn
- **Puerto**: 8000
- **Health Check**: `/health`
- **API Docs**: `/docs` (Swagger UI)
- **Arquitecturas**: AMD64, ARM64

**Uso directo:**
```bash
# Ejecutar directamente
docker run -p 8000:8000 ogaston/inference-g3:latest

# Verificar funcionamiento
curl http://localhost:8000/health
```

---

## üìÅ Estructura del Proyecto

```
Taller-5/
‚îú‚îÄ‚îÄ docker-compose.yaml                  # Compose principal (NO modificar)
‚îú‚îÄ‚îÄ docker-compose.locust.yml            # ‚ú® Compose para Locust (OPTIMIZADO)
‚îú‚îÄ‚îÄ docker-compose.locust-minimal.yml    # ‚ú® Compose minimalista (NUEVO)
‚îú‚îÄ‚îÄ docker-compose.inference-simple.yml  # ‚ú® Compose simple
‚îú‚îÄ‚îÄ .env                                 # Variables originales (NO modificar)
‚îú‚îÄ‚îÄ env.locust                          # ‚ú® Variables para Locust
‚îú‚îÄ‚îÄ locustfile.py                       # ‚ú® Configuraci√≥n de pruebas (OPTIMIZADO)
‚îú‚îÄ‚îÄ nginx.conf                          # ‚ú® Load balancer
‚îú‚îÄ‚îÄ run_load_tests.sh                   # ‚ú® Script automatizado (OPTIMIZADO)
‚îú‚îÄ‚îÄ set_resources.sh                    # ‚ú® Script para cambiar recursos (NUEVO)
‚îú‚îÄ‚îÄ test_complete.sh                    # ‚ú® Suite completa de pruebas (NUEVO)
‚îú‚îÄ‚îÄ Makefile.locust                     # ‚ú® Comandos √∫tiles (OPTIMIZADO)
‚îú‚îÄ‚îÄ Dockerfile.inference                # Dockerfile de la API
‚îú‚îÄ‚îÄ README-LOCUST.md                    # Documentaci√≥n detallada
‚îú‚îÄ‚îÄ INICIO-RAPIDO-LOCUST.md            # Gu√≠a r√°pida
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ train_standalone.py            # Script de entrenamiento
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                        # API FastAPI
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt               # Dependencias
‚îú‚îÄ‚îÄ mysql/
‚îÇ   ‚îî‚îÄ‚îÄ init/
‚îÇ       ‚îî‚îÄ‚îÄ 01-create-schema.sql       # Schema de BD
‚îî‚îÄ‚îÄ load_test_results/                 # Resultados de pruebas
```

---

## üöÄ Optimizaciones Implementadas (v2.0)

### ‚ú® **Nuevas Caracter√≠sticas**

- **‚ö° Inicio s√∫per r√°pido**: 30 segundos vs 3 minutos
- **üì¶ Configuraci√≥n minimalista**: Solo 3 servicios esenciales
- **üõ†Ô∏è Scripts de utilidad**: Cambio din√°mico de recursos
- **‚ö° Suite completa**: Pruebas automatizadas con reportes
- **üîß Compatibilidad ARM64**: Funciona en Mac M1/M2
- **üìä Docker Compose v2**: Compatible con versiones modernas

### üîß **Configuraciones Disponibles**

#### **1. Configuraci√≥n Minimalista (Recomendada)**
```bash
# Archivo: docker-compose.locust-minimal.yml
# Servicios: 3 (inference-api, locust-master, locust-worker)
# Tiempo de inicio: ~30 segundos
# Uso: Desarrollo y pruebas r√°pidas

make -f Makefile.locust up
```

#### **2. Configuraci√≥n Completa (Opcional)**
```bash
# Archivo: docker-compose.locust.yml
# Servicios: 6 (mysql, mlflow, nginx, inference-api, locust-master, locust-worker)
# Tiempo de inicio: ~2-3 minutos
# Uso: Testing completo con MLflow

make -f Makefile.locust up-full
```

### üõ†Ô∏è **Nuevos Scripts de Utilidad**

#### **Cambiar Recursos Din√°micamente**
```bash
# Cambiar a 1 CPU, 1GB RAM
./set_resources.sh 1.0 1G

# Cambiar a 2 CPU, 2GB RAM
./set_resources.sh 2.0 2G
```

#### **Suite Completa de Pruebas**
```bash
# Ejecutar todas las configuraciones autom√°ticamente
./test_complete.sh

# Configuraciones probadas:
# - 0.25 CPU, 256M RAM, 500 usuarios
# - 0.5 CPU, 512M RAM, 2000 usuarios  
# - 1.0 CPU, 1G RAM, 5000 usuarios
# - 2.0 CPU, 2G RAM, 10000 usuarios
```

### üìä **Configuraciones Predefinidas Optimizadas**

```bash
# Prueba r√°pida (500 usuarios, 5min)
./run_load_tests.sh quick

# Prueba media (2000 usuarios, 10min)
./run_load_tests.sh medium

# Prueba de carga (5000 usuarios, 15min)
./run_load_tests.sh load

# Prueba de estr√©s (10000 usuarios, 20min)
./run_load_tests.sh stress
```

---

## üîß Requisitos Previos

- **Docker** 20.10+
- **Docker Compose** 2.0+
- **curl** (para health checks)
- **make** (opcional, para comandos simplificados)
- **8GB RAM** m√≠nimo
- **10GB** espacio en disco

### Verificar instalaci√≥n:
```bash
docker --version
docker compose version
curl --version
make --version  # opcional
```

---

## ‚ö° Inicio R√°pido (3 pasos)

### 1Ô∏è‚É£ Iniciar servicios con Locust
```bash
# Opci√≥n A: Con Make (recomendado)
make -f Makefile.locust up

# Opci√≥n B: Con Docker Compose
docker compose -f docker-compose.locust.yml up -d
```

### 2Ô∏è‚É£ Verificar que todo est√° funcionando
```bash
# Health check de la API
curl http://localhost:8000/health

# Ver estado de contenedores
docker compose -f docker-compose.locust.yml ps

# Ver logs en tiempo real
docker compose -f docker-compose.locust.yml logs -f
```

### 3Ô∏è‚É£ Acceder a Locust UI
Abre tu navegador en: **http://localhost:8089**

Configuraci√≥n inicial:
- **Number of users**: 100
- **Spawn rate**: 10
- **Host**: http://inference-api:8000 (ya configurado)

Click en **"Start swarming"** üöÄ

---

## üéÆ Uso con Make (Optimizado)

El `Makefile.locust` proporciona comandos simplificados y optimizados:

```bash
# Ver todos los comandos disponibles
make -f Makefile.locust help

# Gesti√≥n b√°sica
make -f Makefile.locust up          # Iniciar servicios (minimalista)
make -f Makefile.locust up-full     # Iniciar servicios completos
make -f Makefile.locust down        # Detener servicios
make -f Makefile.locust logs        # Ver logs
make -f Makefile.locust stats       # Ver estad√≠sticas
make -f Makefile.locust status      # Verificar estado

# Pruebas predefinidas optimizadas
make -f Makefile.locust test-quick   # 500 usuarios, 5 min
make -f Makefile.locust test-medium  # 2000 usuarios, 10 min
make -f Makefile.locust test-load    # 5000 usuarios, 15 min
make -f Makefile.locust test-stress  # 10000 usuarios, 20 min

# Utilidades avanzadas
make -f Makefile.locust scale N=3    # Escalar workers
make -f Makefile.locust restart-api  # Reiniciar solo la API

# Limpieza
make -f Makefile.locust clean       # Limpiar todo
```

---

## üß™ Pruebas de Carga

### M√©todo 1: UI Web de Locust

1. Iniciar servicios: `make -f Makefile.locust up`
2. Abrir: http://localhost:8089
3. Configurar usuarios y spawn rate
4. Click en "Start swarming"
5. Monitorear en tiempo real

### M√©todo 2: Script Automatizado

```bash
# Dar permisos de ejecuci√≥n
chmod +x run_load_tests.sh

# Prueba r√°pida
./run_load_tests.sh --quick

# Prueba media
./run_load_tests.sh --medium

# Todas las pruebas
./run_load_tests.sh --full

# Configuraci√≥n espec√≠fica
./run_load_tests.sh --config 0.5/512M

# Personalizada
./run_load_tests.sh --users 1000 --time 10m
```

### M√©todo 3: Locust Headless

```bash
docker compose -f docker-compose.locust.yml exec locust-master locust \
  --locustfile=/mnt/locust/locustfile.py \
  --host=http://inference-api:8000 \
  --users=100 \
  --spawn-rate=10 \
  --run-time=5m \
  --headless
```

---

## üîß Configuraci√≥n de Recursos

### **M√©todo 1: Script Automatizado (Recomendado)**

```bash
# Cambiar recursos din√°micamente
./set_resources.sh 1.0 1G    # 1 CPU, 1GB RAM
./set_resources.sh 2.0 2G    # 2 CPU, 2GB RAM
./set_resources.sh 0.5 512M  # 0.5 CPU, 512MB RAM

# El script autom√°ticamente:
# - Actualiza env.locust
# - Reinicia la API con nuevos recursos
# - Verifica que est√© funcionando
```

### **M√©todo 2: Editar archivos manualmente**

#### Editar l√≠mites en `docker-compose.locust.yml`:

```yaml
inference-api:
  deploy:
    resources:
      limits:
        cpus: '0.5'      # Cambiar aqu√≠
        memory: 512M     # Cambiar aqu√≠
```

#### O usar variables de entorno en `env.locust`:

```bash
# Editar archivo
nano env.locust

# Cambiar estos valores
API_CPU_LIMIT=0.5
API_MEMORY_LIMIT=512M
```

### **Reiniciar con nueva configuraci√≥n:**

```bash
# Con script automatizado (recomendado)
./set_resources.sh 1.0 1G

# O manualmente
make -f Makefile.locust restart
```

---

## üìä Configuraciones Recomendadas

| Escenario | CPU | RAM | Usuarios Max | Uso |
|-----------|-----|-----|--------------|-----|
| Desarrollo | 0.25 | 256M | 500 | Pruebas locales |
| Testing | 0.5 | 512M | 2,000 | CI/CD |
| Pre-producci√≥n | 1.0 | 1G | 5,000 | Staging |
| Producci√≥n | 2.0 | 2G | 10,000+ | Prod |

---

## üéØ Flujo de Trabajo del Taller

### Paso 1: Configuraci√≥n Base (0.5 CPU, 512M RAM)

```bash
# 1. Iniciar servicios
make -f Makefile.locust up

# 2. Verificar health
curl http://localhost:8000/health

# 3. Prueba con 100 usuarios (UI)
open http://localhost:8089
```

### Paso 2: Incrementar usuarios gradualmente

```
100 usuarios   ‚Üí ‚úÖ OK
500 usuarios   ‚Üí ‚úÖ OK
1000 usuarios  ‚Üí ‚úÖ OK
2000 usuarios  ‚Üí ‚ö†Ô∏è  Latencia alta
5000 usuarios  ‚Üí ‚ùå Failures > 5%
```

### Paso 3: Ajustar recursos

```bash
# Editar docker-compose.locust.yml
cpus: '1.0'
memory: 1G

# Reiniciar
make -f Makefile.locust restart

# Probar de nuevo con 5000 usuarios
```

### Paso 4: Encontrar configuraci√≥n √≥ptima

Repetir hasta encontrar el m√≠nimo de recursos que soporten 10,000 usuarios con:
- ‚úÖ Failures < 1%
- ‚úÖ P95 Latency < 1s
- ‚úÖ CPU < 90%
- ‚úÖ RAM < 90%

### Paso 5: Documentar resultados

Completar tabla en `REPORTE.md`:

| CPU | RAM | Users | RPS | P95 (ms) | Failures | Resultado |
|-----|-----|-------|-----|----------|----------|-----------|
| 0.5 | 512M | 2000 | 200 | 800 | 0.5% | ‚ö†Ô∏è L√≠mite |
| 1.0 | 1G | 5000 | 500 | 600 | 0.8% | ‚úÖ OK |
| 2.0 | 2G | 10000 | 1000 | 400 | 0.5% | ‚úÖ OK |

---

## üîÄ Escalamiento con R√©plicas

### M√©todo 1: Docker Compose Scale

```bash
# Escalar a 3 instancias
docker compose -f docker-compose.locust.yml up -d --scale inference-api=3

# Verificar
docker ps | grep inference-api

# O con Make
make -f Makefile.locust scale-3
```

### M√©todo 2: Con Nginx Load Balancer

El archivo `nginx.conf` ya est√° configurado para balancear entre 3 r√©plicas.

```bash
# Nginx ya est√° en docker-compose.locust.yml
# Autom√°ticamente distribuye la carga

# Ver logs de Nginx
docker logs nginx-locust
```

---

## üìà Monitoreo en Tiempo Real

### Ver estad√≠sticas de Docker:

```bash
# Estad√≠sticas generales
docker stats

# Solo API de inferencia
docker stats inference-api-locust

# O con Make
make -f Makefile.locust stats
```

### Ver logs:

```bash
# Todos los logs
make -f Makefile.locust logs

# Solo API
make -f Makefile.locust logs-api

# Solo Locust
make -f Makefile.locust logs-locust
```

### M√©tricas de Locust:

- **UI Web**: http://localhost:8089
- **Gr√°ficos en tiempo real**: Total RPS, Response times, Failures
- **Tablas**: Requests, Failures, Statistics

---

## üìÅ Resultados de Pruebas

Los resultados se guardan autom√°ticamente en `load_test_results/`:

```bash
load_test_results/
‚îú‚îÄ‚îÄ test_500users_0.5cpu_512Mmem_5m_stats.csv    # Datos CSV
‚îú‚îÄ‚îÄ test_500users_0.5cpu_512Mmem_5m.html         # Reporte HTML
‚îî‚îÄ‚îÄ consolidated_report.md                        # Reporte consolidado
```

### Interpretar archivos CSV:

- **Request Count**: Total de peticiones
- **Failure Count**: Peticiones fallidas
- **Median Response Time**: Tiempo de respuesta mediano
- **95th Percentile**: 95% de respuestas en este tiempo
- **Requests/s**: RPS promedio

### Ver resultados:

```bash
# Listar archivos
ls -lh load_test_results/

# Ver reporte consolidado
cat load_test_results/consolidated_report.md

# Abrir HTML en navegador
open load_test_results/*.html
```

---

## üêõ Troubleshooting

### Servicios no inician

```bash
# Ver logs completos
docker compose -f docker-compose.locust.yml logs

# Verificar puertos en uso
lsof -i :8000
lsof -i :8089
lsof -i :5002

# Limpiar y reiniciar
make -f Makefile.locust clean
make -f Makefile.locust up
```

### API no responde

```bash
# Health check
curl -v http://localhost:8000/health

# Logs de la API
docker logs inference-api-locust

# Reiniciar solo la API
docker restart inference-api-locust
```

### Locust no conecta a la API

```bash
# Verificar red
docker network inspect locust-network

# Verificar DNS interno
docker compose -f docker-compose.locust.yml exec locust-master ping inference-api

# Ver logs de Locust
docker logs locust-master
```

### Errores de memoria/CPU

```bash
# Ver uso actual
docker stats

# Aumentar l√≠mites
# Editar docker-compose.locust.yml:
cpus: '2.0'
memory: 2G

# Reiniciar
make -f Makefile.locust restart
```

### Puerto 8089 en uso

```bash
# Ver qu√© lo usa
lsof -i :8089

# Cambiar puerto en docker-compose.locust.yml:
ports:
  - "8090:8089"
```

---

## üìö Archivos de Documentaci√≥n

- **README.md** (este archivo): Gu√≠a completa del taller con optimizaciones v2.0
- **README-LOCUST.md**: Documentaci√≥n t√©cnica detallada (optimizada)
- **INICIO-RAPIDO-LOCUST.md**: Comandos esenciales y gu√≠a r√°pida

### **Nuevos Archivos de Utilidad**

- **`set_resources.sh`**: Script para cambiar recursos din√°micamente
- **`test_complete.sh`**: Suite completa de pruebas automatizada
- **`docker-compose.locust-minimal.yml`**: Configuraci√≥n minimalista optimizada

---

## üéì Preguntas del Taller

### 1. ¬øEs posible reducir m√°s los recursos?

**Respuesta**: Depende del modelo:
- Modelo simple (sklearn): Hasta 0.25 CPU + 256MB
- Modelo complejo (deep learning): M√≠nimo 1 CPU + 1GB

### 2. ¬øCu√°l es la mayor cantidad de peticiones soportadas?

**Respuesta t√≠pica**:
- 1 instancia (2 CPU, 2GB): ~1,000 RPS
- 3 instancias (0.75 CPU, 768MB c/u): ~3,000 RPS
- L√≠mite: Depende del hardware del host

### 3. ¬øQu√© diferencia hay entre 1 o m√∫ltiples instancias?

| Aspecto | 1 Instancia | 3 Instancias |
|---------|-------------|--------------|
| **Throughput** | Menor | Mayor |
| **Latencia** | Mayor bajo carga | Menor |
| **Disponibilidad** | Sin redundancia | Alta disponibilidad |
| **Escalabilidad** | Vertical (m√°s recursos) | Horizontal (m√°s instancias) |
| **Costo** | M√°s recursos por instancia | Recursos distribuidos |

---

## üßπ Limpieza

### Detener servicios:

```bash
make -f Makefile.locust down
```

### Limpiar contenedores y vol√∫menes:

```bash
make -f Makefile.locust clean
```

### Limpiar solo resultados:

```bash
make -f Makefile.locust clean-results
```

### Limpieza completa del sistema:

```bash
docker system prune -a --volumes
```

---

## üîó URLs de Acceso

Una vez iniciados los servicios:

| Servicio | URL | Descripci√≥n |
|----------|-----|-------------|
| **Locust UI** | http://localhost:8089 | Interfaz de pruebas |
| **API** | http://localhost:8000 | API de inferencia |
| **API Health** | http://localhost:8000/health | Health check |
| **API Docs** | http://localhost:8000/docs | Swagger UI |
| **MLflow** | http://localhost:5002 | Tracking UI |
| **MySQL** | localhost:3306 | Base de datos |
| **Nginx** | http://localhost:80 | Load balancer |

---

## üìä Ejemplo de Payload

Para hacer predicciones manuales:

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "elevation": 2500,
    "aspect": 180,
    "slope": 15,
    "horizontal_distance_to_hydrology": 200,
    "vertical_distance_to_hydrology": 50,
    "horizontal_distance_to_roadways": 1000,
    "hillshade_9am": 200,
    "hillshade_noon": 230,
    "hillshade_3pm": 150,
    "horizontal_distance_to_fire_points": 800,
    "wilderness_area": 1,
    "soil_type": 10
  }'
```

Respuesta esperada:
```json
{
  "prediction": 3,
  "confidence": 0.95,
  "model_version": "1.0.0"
}
```

---

## üë• Equipo

- **Grupo 3**: Abel Albuez Sanchez, Omar Gaston Chalas, Mauricio Morales
- **Imagen Docker**: ogaston/inference-g3:latest
- **Modelo**: Covertype Classification (12 features)

---

## üìÑ Licencia

Este proyecto es parte del curso de MLOps - 2024

---

## ‚úÖ Checklist de Validaci√≥n

Antes de entregar el taller, verifica:

- [ ] Imagen publicada en DockerHub
- [ ] Docker Compose funciona correctamente
- [ ] Locust UI accesible en http://localhost:8089
- [ ] API responde en http://localhost:8000/health
- [ ] Pruebas ejecutadas con diferentes configuraciones
- [ ] Resultados documentados en `load_test_results/`
- [ ] Tabla de resultados completa
- [ ] An√°lisis de 1 vs m√∫ltiples instancias
- [ ] Screenshots de evidencia
- [ ] Reporte final escrito

---

## üÜò Soporte

Para problemas:

1. Revisar secci√≥n de **Troubleshooting**
2. Ver logs: `make -f Makefile.locust logs`
3. Consultar **README-LOCUST.md** para detalles t√©cnicos
4. Revisar **INICIO-RAPIDO-LOCUST.md** para comandos b√°sicos

---