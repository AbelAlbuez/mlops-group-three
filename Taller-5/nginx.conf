# Configuración de Nginx como load balancer para múltiples réplicas de la API de inferencia
# Este archivo se usa en docker-compose.locust.yml para distribuir la carga

events {
    worker_connections 1024;
}

http {
    # Configuración básica
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;
    
    # Configuración de logs
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';
    
    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log warn;
    
    # Configuración de performance
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    
    # Configuración de buffers
    client_body_buffer_size 128k;
    client_max_body_size 10m;
    client_header_buffer_size 1k;
    large_client_header_buffers 4 4k;
    
    # Configuración de timeouts
    client_body_timeout 12;
    client_header_timeout 12;
    keepalive_timeout 15;
    send_timeout 10;
    
    # Configuración de compresión
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;
    
    # Upstream para la API de inferencia
    upstream inference_api {
        # Algoritmo de balanceo: least_conn (menos conexiones activas)
        least_conn;
        
        # Servidores de la API de inferencia
        server inference-api:8000 max_fails=3 fail_timeout=30s;
        server inference-api-2:8000 max_fails=3 fail_timeout=30s;
        server inference-api-3:8000 max_fails=3 fail_timeout=30s;
        
        # Configuración de health checks
        keepalive 32;
    }
    
    # Upstream para MLflow (si es necesario)
    upstream mlflow_backend {
        server mlflow:5000;
        keepalive 16;
    }
    
    # Servidor principal
    server {
        listen 80;
        server_name localhost;
        
        # Configuración de logs específicos
        access_log /var/log/nginx/inference_access.log main;
        error_log /var/log/nginx/inference_error.log;
        
        # Configuración de headers
        add_header X-Content-Type-Options nosniff;
        add_header X-Frame-Options DENY;
        add_header X-XSS-Protection "1; mode=block";
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
        
        # Endpoint principal para predicciones
        location / {
            # Proxy a la API de inferencia
            proxy_pass http://inference_api;
            
            # Headers de proxy
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Configuración de timeouts
            proxy_connect_timeout 30s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
            
            # Configuración de buffers
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
            proxy_busy_buffers_size 8k;
            
            # Configuración de retry
            proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
            proxy_next_upstream_tries 3;
            proxy_next_upstream_timeout 10s;
            
            # Configuración de keepalive
            proxy_http_version 1.1;
            proxy_set_header Connection "";
        }
        
        # Endpoint específico para health checks
        location /health {
            proxy_pass http://inference_api/health;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Timeouts más cortos para health checks
            proxy_connect_timeout 5s;
            proxy_send_timeout 5s;
            proxy_read_timeout 5s;
        }
        
        # Endpoint para predicciones específico
        location /predict {
            proxy_pass http://inference_api/predict;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Configuración específica para predicciones
            proxy_connect_timeout 30s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
            
            # Configuración de buffers para respuestas grandes
            proxy_buffering on;
            proxy_buffer_size 8k;
            proxy_buffers 16 8k;
            proxy_busy_buffers_size 16k;
        }
        
        # Endpoint para métricas de Nginx
        location /nginx_status {
            stub_status on;
            access_log off;
            allow 127.0.0.1;
            allow 172.0.0.0/8;
            allow 10.0.0.0/8;
            deny all;
        }
        
        # Endpoint para información del load balancer
        location /lb_info {
            return 200 '{"load_balancer": "nginx", "upstream": "inference_api", "algorithm": "least_conn", "servers": 3}';
            add_header Content-Type application/json;
        }
        
        # Configuración de error pages
        error_page 500 502 503 504 /50x.html;
        location = /50x.html {
            root /usr/share/nginx/html;
        }
    }
    
    # Servidor para MLflow (opcional)
    server {
        listen 5001;
        server_name localhost;
        
        location / {
            proxy_pass http://mlflow_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}
