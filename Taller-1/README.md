# Palmer Penguins Classifier API

API REST para clasificaciÃ³n de especies de pingÃ¼inos usando mÃºltiples modelos de Machine Learning (Random Forest, KNN, SVM).

## ğŸ“‹ DescripciÃ³n

Esta API permite predecir la especie de pingÃ¼ino (Adelie, Chinstrap o Gentoo) basÃ¡ndose en caracterÃ­sticas fÃ­sicas como el tamaÃ±o del pico, aletas y masa corporal. Incluye la funcionalidad de seleccionar entre diferentes modelos entrenados.

## ğŸš€ Inicio RÃ¡pido

### Prerequisitos
- Python 3.8+
- Docker (opcional)

### InstalaciÃ³n Local

1. **Clonar el repositorio**
```bash
git clone https://github.com/AbelAlbuez/mlops-group-three.git
cd mlops-group-three/Taller-1
```

2. **Crear entorno virtual**
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Ejecutar la API**
```bash
python api.py
```

La API estarÃ¡ disponible en `http://localhost:5000`

## ğŸ³ InstalaciÃ³n con Docker

1. **Construir la imagen**
```bash
docker build -t palmer-penguins-api .
```

2. **Ejecutar el contenedor**
```bash
docker run -p 5000:5000 palmer-penguins-api
```

## ğŸ“š Estructura del Proyecto

```
Taller-1/
â”œâ”€â”€ api.py                  # API Flask principal
â”œâ”€â”€ Modelos/               # Directorio con modelos entrenados
â”‚   â”œâ”€â”€ knn_model.pkl
â”‚   â”œâ”€â”€ random_forest_model.pkl
â”‚   â””â”€â”€ svm_model.pkl
â”œâ”€â”€ migrate_models.py      # Script para migraciÃ³n de modelos
â”œâ”€â”€ requirements.txt       # Dependencias del proyecto
â”œâ”€â”€ smoke_test.py         # Tests bÃ¡sicos de la API
â”œâ”€â”€ Dockerfile            # ConfiguraciÃ³n Docker
â”œâ”€â”€ .gitignore           # Archivos ignorados por Git
â””â”€â”€ README.md            # Este archivo
```

## ğŸ”§ Uso de la API

### Endpoints Disponibles

#### 1. Health Check
```bash
GET /health
```

Respuesta:
```json
{
  "status": "ok"
}
```

#### 2. PredicciÃ³n de Especie
```bash
POST /predict
```

**ParÃ¡metros del body (JSON):**
```json
{
  "culmen_length_mm": 39.1,
  "culmen_depth_mm": 18.7,
  "flipper_length_mm": 181,
  "body_mass_g": 3750,
  "model_type": "random_forest"  // Opciones: "random_forest", "knn", "svm"
}
```

**Respuesta exitosa:**
```json
{
  "species": "Adelie",
  "model_used": "random_forest",
  "confidence": 0.95
}
```

### Ejemplos de Uso

#### Con cURL:
```bash
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "culmen_length_mm": 39.1,
    "culmen_depth_mm": 18.7,
    "flipper_length_mm": 181,
    "body_mass_g": 3750,
    "model_type": "random_forest"
  }'
```

#### Con Python:
```python
import requests

url = "http://localhost:5000/predict"
data = {
    "culmen_length_mm": 39.1,
    "culmen_depth_mm": 18.7,
    "flipper_length_mm": 181,
    "body_mass_g": 3750,
    "model_type": "knn"
}

response = requests.post(url, json=data)
print(response.json())
```

## ğŸ“Š Modelos Disponibles

1. **Random Forest** (por defecto)
   - Alta precisiÃ³n
   - Robusto ante outliers
   - Mejor rendimiento general

2. **K-Nearest Neighbors (KNN)**
   - Simple y efectivo
   - Bueno para patrones locales
   - Sensible a la escala de datos

3. **Support Vector Machine (SVM)**
   - Excelente para separaciÃ³n no lineal
   - Eficiente en espacios de alta dimensiÃ³n
   - Robusto ante overfitting

## ğŸ§ª Testing

Ejecutar el test de smoke:
```bash
python smoke_test.py
```

Este script verifica:
- ConexiÃ³n a la API
- Endpoint de health check
- Predicciones con cada modelo
- Manejo de errores

## ğŸ“ˆ CaracterÃ­sticas de los Datos

Las caracterÃ­sticas utilizadas para la predicciÃ³n son:
- **culmen_length_mm**: Longitud del pico (mm)
- **culmen_depth_mm**: Profundidad del pico (mm)
- **flipper_length_mm**: Longitud de la aleta (mm)
- **body_mass_g**: Masa corporal (g)

Especies predichas:
- Adelie
- Chinstrap
- Gentoo

## ğŸ”„ MigraciÃ³n de Modelos

Para actualizar o migrar modelos existentes:
```bash
python migrate_models.py
```

Este script permite:
- Cargar modelos antiguos
- Validar su funcionamiento
- Guardar en el nuevo formato
- Verificar compatibilidad

## ğŸ› ï¸ Desarrollo

### Dependencias Principales
- Flask: Framework web
- scikit-learn: Modelos de ML
- pandas: ManipulaciÃ³n de datos
- numpy: Operaciones numÃ©ricas
- pickle: SerializaciÃ³n de modelos

### Agregar un Nuevo Modelo

1. Entrenar el modelo usando el dataset Palmer Penguins
2. Guardar el modelo en formato pickle en `Modelos/`
3. Actualizar `api.py` para incluir el nuevo modelo
4. Actualizar la documentaciÃ³n

## ğŸ“ Notas Importantes

- Los modelos estÃ¡n pre-entrenados con el dataset Palmer Penguins
- AsegÃºrate de que todos los valores de entrada sean numÃ©ricos
- Los valores faltantes deben ser manejados antes de la predicciÃ³n
- La API valida automÃ¡ticamente los rangos de valores esperados

## ğŸ¤ Contribuir

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo LICENSE para mÃ¡s detalles.

## ğŸ‘¥ Autores

- **Abel Albuez** - [GitHub](https://github.com/AbelAlbuez)
- **Omar GastÃ³n**
- **Mauricio Morales**

Grupo 3 - MLOps

## ğŸ™ Agradecimientos

- Dataset Palmer Penguins por Allison Horst
- Comunidad de scikit-learn
- Flask por su excelente framework